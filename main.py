#!/usr/bin/python3
# -*- coding: utf-8 -*-
# You can import anything standard python, numpy, or pandas.
import numpy as np
import numpy.typing as npt


def import_data(filename: str) -> tuple[npt.NDArray[np.float64], npt.NDArray[np.int64]]:
    """
    Imports csv data, processes it, and returns it ready for learning.
    Be careful not to keep the "breast cancer" column in your X data!
    Doing so would be allowing your model to peek at the answer...

    Parameters
    ----------
    filename : str
        Either the train or test data in this directory.

    Returns
    -------
    data : np.ndarray
        The X data vectors.
    target : np.ndarray
        The single y colum vector.
    """
    import pandas as pd

    df = pd.read_csv(filename)
    y = df["breast cancer"].to_numpy(dtype=np.int64)
    X = df.drop(columns=["breast cancer"]).to_numpy(dtype=np.float64)
    return X, y


class MyLearner:
    def __init__(self) -> None:
        """
        Any initialization you'd like to do should go here.
        """
        self.k: int = 5
        self.X_train: npt.NDArray[np.float64] | None = None
        self.y_train: npt.NDArray[np.int64] | None = None

    def fit(self, data: npt.NDArray[np.float64], target: npt.NDArray[np.int64]) -> None:
        """
        This should take in the data X vectors, and the y target vector,
        and train the model, storing it as an instance variable.
        """
        self.X_train = data
        self.y_train = target

    def predict(self, data: npt.NDArray[np.float64]) -> npt.NDArray[np.int64]:
        """
        This function should predict from data alone.
        It should return an np.array with the predicted classes,
        generated by whatever model you choose to implement or use.
        """
        assert self.X_train is not None and self.y_train is not None
        predictions = []
        for x in data:
            distances = np.linalg.norm(self.X_train - x, axis=1)
            k_indices = np.argsort(distances)[: self.k]
            k_nearest_labels = self.y_train[k_indices]
            label = np.bincount(k_nearest_labels).argmax()
            predictions.append(label)
        return np.array(predictions, dtype=np.int64)


def main() -> None:
    X, y = import_data("GSE73002_breast_cancer_train.csv")
    my_learner = MyLearner()
    my_learner.fit(data=X, target=y)

    # Validation test
    my_results = my_learner.predict(data=X)
    your_score = list(y == my_results).count(True) / len(y)
    print("Testing on the train set (statistical cheating):", your_score)

    # Real test of generalization
    X, y = import_data("GSE73002_breast_cancer_test.csv")
    my_results = my_learner.predict(data=X)
    your_score = list(y == my_results).count(True) / len(y)
    print("Testing on the test set (fair):", your_score)


if __name__ == "__main__":
    main()
